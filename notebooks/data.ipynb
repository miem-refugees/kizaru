{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv sync --group notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/data.csv', quoting=1)  # quoting=1 means QUOTE_ALL\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nBasic statistics for text column:\")\n",
    "print(\"Number of unique texts:\", df['text'].nunique())\n",
    "print(\"Average text length:\", df['text'].str.len().mean())\n",
    "print(\"Max text length:\", df['text'].str.len().max())\n",
    "print(\"Min text length:\", df['text'].str.len().min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['text'].dropna().astype(str)).replace('\\\\n', ' ').lower()\n",
    "\n",
    "# Generate a word cloud object, skipping stopwords and \\n\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    collocations=False,\n",
    "    stopwords=stopwords\n",
    ").generate(text)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = df['text'].dropna().str.split().apply(len).sum()\n",
    "print(\"Total number of words:\", total_words)\n",
    "\n",
    "all_words = ' '.join(df['text'].dropna().astype(str)).lower().split()\n",
    "unique_words = set(all_words)\n",
    "print(\"Number of unique words:\", len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "filtered_words = [word for word in all_words if word not in stopwords and word.isalpha()]\n",
    "word_counts = Counter(filtered_words)\n",
    "print(\"Top 10 most common words (excluding stopwords):\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = df['text'].dropna().str.split().apply(len)\n",
    "print(\"Average text length (in words):\", text_lengths.mean())\n",
    "print(\"Max text length (in words):\", text_lengths.max())\n",
    "print(\"Min text length (in words):\", text_lengths.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
